{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: End to end model training and validation with Pytorch, Ignite and MONAI\n",
    "---\n",
    "## Overview\n",
    "\n",
    "This notebook takes you through the end to end workflow using for training a deep learning model.  You'll do the following:\n",
    "- Download the MedNIST Dataset\n",
    "- Explore the data\n",
    "- Prepare training, validation, and test datasets\n",
    "- Use MONAI transforms, dataset, and dataloader\n",
    "- Define network, optimizer, and loss function\n",
    "- Train your model with a standard pytorch training loop\n",
    "- Plot your training metrics\n",
    "- Evaluate your model on a test set\n",
    "- Understand your results\n",
    "- Make some improvements\n",
    "  - Revisit model training using ignite and MONAI features\n",
    "  - Sort out problems limiting reproducability\n",
    "  - Rework dataset partitioning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import everything that we'll need from MONAI\n",
    "Initial imports of the various packages used to create a model using pytorch and MONAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \"monai==0.3.0rc2\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.metrics import compute_roc_auc\n",
    "from monai.networks.nets import densenet121\n",
    "from monai.transforms import (\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    LoadPNG,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "We'll create a temporary directory for all the MONAI data we're going to be using called MONAI_DATA_DIRECTORY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the MedNIST dataset\n",
    "The `MedNIST` dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions),\n",
    "[the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4),\n",
    "and [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
    "\n",
    "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)\n",
    "under the Creative Commons [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "If you use the MedNIST dataset, please acknowledge the source.\n",
    "\n",
    "We're going to download this dataset below and extract it into our temporary MONAI Data Directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = \"https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz?dl=1\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set deterministic training for reproducibility\n",
    "[set_determinism](https://docs.monai.io/en/latest/utils.html?highlight=set_determinism#monai.utils.misc.set_determinism) will set the random seeds in both Numpy and PyTorch to ensure reproducibility. We'll see later that we need to go a little bit further to ensure reproducibility in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the image filenames from the dataset folders\n",
    "\n",
    "When using a dataset, you want to understand the basics of the images, labels, and more.  We'll start off by showing some of those basic statistics for MedNIST.\n",
    "\n",
    "We'll see that 6 different folders are representing 6 different categories: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT.  We'll be using each of these categories as our label names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "image_class = []\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly pick images from the dataset to visualize and check\n",
    "\n",
    "We want to understand what the images we're using look like, so we'll start by visualizing a few random images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i, k in enumerate(np.random.randint(num_total, size=9)):\n",
    "    im = PIL.Image.open(image_files_list[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[image_class[k]])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training, validation, and test data lists\n",
    "\n",
    "We want to split the data into 3 different sets, one for training, one for validation, and one for testing.  We'll use a ratio of 80/10/10 for those sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_frac = 0.1\n",
    "test_frac = 0.1\n",
    "train_x = list()\n",
    "train_y = list()\n",
    "val_x = list()\n",
    "val_y = list()\n",
    "test_x = list()\n",
    "test_y = list()\n",
    "\n",
    "for i in range(num_total):\n",
    "    rann = np.random.random()\n",
    "    if rann < val_frac:\n",
    "        val_x.append(image_files_list[i])\n",
    "        val_y.append(image_class[i])\n",
    "    elif rann < test_frac + val_frac:\n",
    "        test_x.append(image_files_list[i])\n",
    "        test_y.append(image_class[i])\n",
    "    else:\n",
    "        train_x.append(image_files_list[i])\n",
    "        train_y.append(image_class[i])\n",
    "\n",
    "print(f\"Training count: {len(train_x)}, Validation count: {len(val_x)}, Test count: {len(test_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MONAI transforms, Dataset and Dataloader to pre-process data\n",
    "\n",
    "We'll define our transform using `Compose`.  In this Array of Transforms, we'll load the image, add a channel, scale its intensity, utilize a few random functions and finally create a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadPNG(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadPNG(image_only=True), AddChannel(), ScaleIntensity(), ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the datasets and loaders for training, validation and test sets\n",
    " * Define a simple dataset, that we'll call `MedNISTDataset`, that groups:\n",
    "   * Images\n",
    "   * Labels\n",
    "   * The transforms that are to be run on the images and labels\n",
    " * Create three instances of this dataset:\n",
    "   * One for training\n",
    "   * One for validation\n",
    "   * One for testing\n",
    "   \n",
    "We'll use a batch size of 512 and employ 10 workers to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_workers = 10\n",
    "\n",
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network and optimizer\n",
    "\n",
    "1. Set `learning_rate` for how much the model is updated per step\n",
    "1. The fetch a pytorch `device` for the GPU\n",
    "1. Instantiate a [densenet121](https://docs.monai.io/en/latest/networks.html?highlight=densenet#monai.networks.nets.densenet121) model instance and 'send' it to the GPU using `device`\n",
    "  * This is a standard MONAI implementation; it is capable of 2D and 3D operation but here we are using it in 2D mode\n",
    "1. We'll make use of the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "device = torch.device(\"cuda:0\")\n",
    "net = densenet121(spatial_dims=2, in_channels=1, out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network training\n",
    "We are hand-rolling a basic pytorch training loop here:\n",
    " * standard pytorch training loop\n",
    "   * step through each training epoch, running through the training set in batches\n",
    "   * after each epoch, run a validation pass, evaluating the network\n",
    "   * if it shows improved performance, save out the model weights\n",
    " * later we will revisit training loops in a more Ignite / MONAI fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 4\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "\n",
    "    epoch_loss = 0\n",
    "    step = 1\n",
    "\n",
    "    steps_per_epoch = len(train_ds) // train_loader.batch_size\n",
    "\n",
    "    # put the network in train mode; this tells the network and its modules to\n",
    "    # enable training elements such as normalisation and dropout, where applicable\n",
    "    net.train()\n",
    "    for batch_data in train_loader:\n",
    "\n",
    "        # move the data to the GPU\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "\n",
    "        # prepare the gradients for this step's back propagation\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run the network forwards\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # run the loss function on the outputs\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # compute the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # tell the optimizer to update the weights according to the gradients\n",
    "        # and its internal optimisation strategy\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size + 1}, training_loss: {loss.item():.4f}\")\n",
    "        step += 1\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # after each epoch, run our metrics to evaluate it, and, if they are an improvement,\n",
    "    # save the model out\n",
    "    \n",
    "    # switch off training features of the network for this pass\n",
    "    net.eval()\n",
    "\n",
    "    # 'with torch.no_grad()' switches off gradient calculation for the scope of its context\n",
    "    with torch.no_grad():\n",
    "        # create lists to which we will concatenate the the validation results\n",
    "        images = list()\n",
    "        labels = list()\n",
    "\n",
    "        # iterate over each batch of images and run them through the network in evaluation mode\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "\n",
    "            # run the network\n",
    "            val_pred = net(val_images)\n",
    "\n",
    "            images.append(val_pred)\n",
    "            labels.append(val_labels)\n",
    "\n",
    "        # concatenate the predicted labels with each other and the actual labels with each other\n",
    "        y_pred = torch.cat(images)\n",
    "        y = torch.cat(labels)\n",
    "\n",
    "        # we are using the area under the receiver operating characteristic (ROC) curve to determine\n",
    "        # whether this epoch has improved the best performance of the network so far, in which case\n",
    "        # we save the network in this state\n",
    "        auc_metric = compute_roc_auc(y_pred, y, to_onehot_y=True, softmax=True)\n",
    "        metric_values.append(auc_metric)\n",
    "        acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "        acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "        if auc_metric > best_metric:\n",
    "            best_metric = auc_metric\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(net.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "            print(\"saved new best metric network\")\n",
    "        print(\n",
    "            f\"current epoch: {epoch + 1} current AUC: {auc_metric:.4f} /\"\n",
    "            f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f} /\"\n",
    "            f\" at epoch: {best_metric_epoch}\"\n",
    "        )\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and metric\n",
    "\n",
    "Once we're done training we want to visualize our Loss and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val AUC\")\n",
    "x = [(i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on the test dataset\n",
    "\n",
    "After training and validation, we now have the best model as determined by the validation dataset.  But now we need to evaluate the model on the test dataset to check whether the final model is robust and not over-fitting.  We'll use these predictions to generate a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "net.eval()\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = net(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some light analytics - classification report\n",
    "\n",
    "We'll utilize scikit-learn's classification report to get the precision, recall, and f1-score for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some light analytics - confusion matrix\n",
    "\n",
    "Let's also create a confusion matrix to get a better understanding of the failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion_matrix(y_true, y_pred), cmap=\"terrain\", interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels(['']+class_names, rotation=270)\n",
    "ax.set_yticklabels(['']+class_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make some changes\n",
    "Everything that we have done so far uses MONAI with pytorch in a very vanilla fashion. The initial training / validation loop is written to show you the nuts and bolts of pytorch. Now let's explore starting the move towards [ignite](https://pytorch.org/ignite/) and features of MONAI designed to work with it. We'll also fix up a couple of outstanding issues that the notebook has in its current form.\n",
    "\n",
    "* MONAI-specific\n",
    "  * Making use of Ignite\n",
    "* Miscellaneous\n",
    "  * Issues with determinism\n",
    "  * Improving dataset partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import Accuracy\n",
    "from monai.handlers import ROCAUC\n",
    "\n",
    "step = 1\n",
    "iter_losses=[]\n",
    "batch_sizes=[]\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "iter_losses=[]\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "# Training\n",
    "\n",
    "# this trainer takes care of the training loop for us\n",
    "trainer = create_supervised_trainer(net, optimizer, loss_function, device, False)\n",
    "\n",
    "# calculate the number of steps per epoch up front\n",
    "steps_per_epoch = len(train_ds) // train_loader.batch_size\n",
    "if len(train_ds) % train_loader.batch_size != 0:\n",
    "    steps_per_epoch += 1\n",
    "\n",
    "\n",
    "# create a handler for recording the loss after each input. Improve upon our earlier example\n",
    "# by also recording the batch size, so we can perform a weighted average for the overall average\n",
    "# loss\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def _end_iter(engine):\n",
    "    global step\n",
    "    loss = engine.state.output\n",
    "    batch_len = len(engine.state.batch[0])\n",
    "    epoch = engine.state.epoch\n",
    "    epoch_len = engine.state.max_epochs\n",
    "    iter_losses.append(loss)\n",
    "    batch_sizes.append(batch_len)\n",
    "    print(f'epoch {epoch}/{epoch_len}, step {step}/{steps_per_epoch}, training_loss = {loss:.4f}')    \n",
    "    step += 1\n",
    "    \n",
    "# Validation\n",
    "\n",
    "val_metrics = {'accuracy': Accuracy(), 'rocauc': ROCAUC(to_onehot_y=True,softmax=True)}\n",
    "evaluator = create_supervised_evaluator(net, val_metrics, device, True)\n",
    "\n",
    "# validation is run every n training epochs in response to the trainer completing\n",
    "# an epoch. Here we use the decorator syntax to add a function that runs it to the\n",
    "# EPOCH_COMPLETED event\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_validation(engine):\n",
    "    global step\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "    # the overall average loss must be weighted by batch size\n",
    "    overall_average_loss = np.average(iter_losses, weights=batch_sizes)\n",
    "    epoch_loss_values.append(overall_average_loss)\n",
    "\n",
    "    # clear the contents of iter_losses and batch_sizes for the next epoch\n",
    "    del iter_losses[:]\n",
    "    del batch_sizes[:]\n",
    "    \n",
    "    # fetch and report the validation metrics\n",
    "    acc = evaluator.state.metrics['accuracy']\n",
    "    roc = evaluator.state.metrics['rocauc']\n",
    "    metric_values.append(roc)\n",
    "    print(f\"evaluation for epoch {engine.state.epoch}, accuracy = {acc:.4f}, rocauc = {roc:.4f}\")\n",
    "\n",
    "    # reset step for the next epoch\n",
    "    step = 1\n",
    "    \n",
    "# create a checkpoint handler to save the network weights based on the area under the ROC curve\n",
    "# as before\n",
    "def _score(_):\n",
    "    return metric_values[-1]\n",
    "\n",
    "# create a model checkpointer to save the network\n",
    "checkpoint_handler = ModelCheckpoint(root_dir, filename_prefix='best_metric_model', score_name='',\n",
    "                                     n_saved=1, require_empty=False, score_function=_score)\n",
    "\n",
    "# handlers are attached to events in trainers and evaluators\n",
    "trainer.add_event_handler(event_name=Events.EPOCH_COMPLETED,\n",
    "                          handler=checkpoint_handler, to_save={'net': net})\n",
    "# train (and evaluate) the network, Ignite-style!\n",
    "train_epochs = 4\n",
    "state = trainer.run(train_loader, train_epochs)\n",
    "\n",
    "best_rocauc = max(metric_values)\n",
    "print(f\"train completed, best_metric: {best_rocauc:.4f} at epoch: {metric_values.index(best_rocauc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues with determinism\n",
    "* MONAI provides `monai.utils.set_determinism` for replicable training\n",
    "  * Easy to accidentally defeat, especially in a jupyter / IPython notebook\n",
    "* How many uses of `numpy.random`'s underlying global instance does this notebook have?\n",
    "  * Dataset partitioning\n",
    "  * Image previewing\n",
    "  * Transforms\n",
    "    * MONAI transforms with randomised behaviour can be given / told to create their own internal `numpy.random.RandomState` instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up transforms, revisited\n",
    "\n",
    "rseed = 12345678\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadPNG(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=15, prob=0.5, keep_size=True).set_random_state(rseed),\n",
    "        RandFlip(spatial_axis=0, prob=0.5).set_random_state(rseed),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5).set_random_state(rseed),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadPNG(image_only=True), AddChannel(), ScaleIntensity(), ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving dataset partitioning\n",
    "  * Current code results in random numbers of images / labels each time it is run\n",
    "  * np.shuffle to the rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "# make this selection deterministic and controllable by seed\n",
    "dataset_seed = 12345678\n",
    "r = np.random.RandomState(dataset_seed)\n",
    "\n",
    "# calculate the number of images we want for the validation and test groups\n",
    "validation_proportion = 0.1\n",
    "test_proportion = 0.1\n",
    "validation_count = floor(validation_proportion * num_total)\n",
    "test_count = floor(test_proportion * num_total)\n",
    "\n",
    "groups = np.zeros(num_total, dtype=np.int32)\n",
    "\n",
    "# set the appropriate number of '1's for the validation dataset\n",
    "groups[:validation_count] = 1\n",
    "\n",
    "# then set the appropriate number of '2's for the test dataset\n",
    "groups[validation_count:validation_count + test_count] = 2\n",
    "\n",
    "# Shuffle the sequence so that \n",
    "r.shuffle(groups)\n",
    "\n",
    "image_sets = list(), list(), list()\n",
    "label_sets = list(), list(), list()\n",
    "\n",
    "for n in range(num_total):\n",
    "    image_sets[groups[n]].append(image_files_list[n])\n",
    "    label_sets[groups[n]].append(image_class[n])\n",
    "    \n",
    "train_x, val_x, test_x = image_sets\n",
    "train_y, val_y, test_y = label_sets\n",
    "print(len(train_x), len(val_x), len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try running the notebook!\n",
    " * Try out the pytorch training loop and the ignite & monai style training loop\n",
    " * Make the entire notebook work deterministically by replacing all implicit use of the global numpy RandomState with explicit RandomState instances\n",
    " * Replace the dataset partitioning with the improved version\n",
    " * Experiment with adding new metrics to the Ignite training / validation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we went through an end-to-end workflow to train the MedNIST dataset using a densenet121 network.  Along the way, you did the following:\n",
    "- Learned about the MedNIST Data and downloaded it\n",
    "- Visualized the data to understand the images we're using\n",
    "- Setup the datasets for use in the model training\n",
    "- Defined our transforms, datasets, network, and optimizers\n",
    "- Trained a densenet model and saved the best model as determined by the validation accuracy\n",
    "- Plotted your training results\n",
    "- Evaluated your model against the test set\n",
    "- Ran your final predictions through a classification report to understand more about your final results\n",
    "\n",
    "For full API documentation, please visit https://docs.monai.io."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy everything up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:monai]",
   "language": "python",
   "name": "conda-env-monai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
